{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Modeling", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Import libraries", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 207, 
            "cell_type": "code", 
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, ElasticNetCV, RidgeCV, LassoCV\nfrom sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\n\n%matplotlib inline", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 208, 
            "cell_type": "code", 
            "source": "df = pd.read_csv('../dataset/preprocessed_data.csv', index_col=0)\ndf", 
            "outputs": [
                {
                    "execution_count": 208, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "      score  rating  price  summer  initial_inspection  0  1  2  3  4  ...   \\\n0      10.0     4.0      1       0                   1  0  1  0  0  0  ...    \n1       7.0     4.0      1       0                   1  0  1  0  0  0  ...    \n2       5.0     4.0      1       0                   1  0  1  0  0  0  ...    \n3       5.0     3.5      0       0                   1  0  0  1  0  0  ...    \n4       6.0     3.5      0       0                   1  0  0  1  0  0  ...    \n5      13.0     3.5      0       0                   1  0  0  1  0  0  ...    \n6      21.0     4.5      0       1                   1  0  0  0  1  0  ...    \n7       6.0     4.5      0       1                   0  0  0  0  1  0  ...    \n8      18.0     4.5      0       0                   1  0  0  0  1  0  ...    \n9       7.0     4.5      0       0                   0  0  0  0  1  0  ...    \n10      8.0     4.5      0       0                   1  0  0  0  1  0  ...    \n11     24.0     4.5      0       0                   1  0  0  0  1  0  ...    \n12     13.0     4.5      0       0                   0  0  0  0  1  0  ...    \n13     11.0     4.5      0       1                   1  0  0  0  1  0  ...    \n14     14.0     2.0      0       0                   1  1  0  0  0  0  ...    \n15     51.0     2.0      0       0                   0  1  0  0  0  0  ...    \n16     33.0     2.0      0       0                   1  1  0  0  0  0  ...    \n17     24.0     2.0      0       0                   0  1  0  0  0  0  ...    \n18     10.0     2.0      0       0                   1  1  0  0  0  0  ...    \n19     27.0     2.0      0       0                   1  1  0  0  0  0  ...    \n20      5.0     2.0      0       0                   0  1  0  0  0  0  ...    \n21     46.0     2.0      0       0                   1  1  0  0  0  0  ...    \n22     11.0     2.0      0       0                   0  1  0  0  0  0  ...    \n23      4.0     2.0      0       0                   0  1  0  0  0  0  ...    \n24     12.0     2.0      0       0                   0  1  0  0  0  0  ...    \n25      7.0     2.0      0       0                   1  0  0  1  0  0  ...    \n26      7.0     1.0      0       0                   1  0  0  1  0  0  ...    \n27      7.0     2.0      0       0                   1  0  0  1  0  0  ...    \n28      7.0     1.0      0       0                   1  0  0  1  0  0  ...    \n29     12.0     2.0      0       0                   1  0  0  1  0  0  ...    \n...     ...     ...    ...     ...                 ... .. .. .. .. ..  ...    \n7650   24.0     3.5      1       0                   0  1  0  0  0  0  ...    \n7651   36.0     3.5      1       0                   0  1  0  0  0  0  ...    \n7652   12.0     3.0      0       0                   0  1  0  0  0  0  ...    \n7653   28.0     5.0      1       0                   0  0  0  1  0  0  ...    \n7654    9.0     5.0      1       0                   0  0  0  1  0  0  ...    \n7655   13.0     2.0      1       0                   0  1  0  0  0  0  ...    \n7656    9.0     2.0      1       0                   0  1  0  0  0  0  ...    \n7657   12.0     3.5      1       0                   0  0  0  0  1  0  ...    \n7658    7.0     4.0      1       0                   0  0  0  1  0  0  ...    \n7659   13.0     4.0      1       0                   0  0  0  1  0  0  ...    \n7660   50.0     3.0      1       0                   0  0  0  0  0  1  ...    \n7661   50.0     3.0      1       0                   0  0  0  0  0  1  ...    \n7662   42.0     3.0      1       0                   0  0  0  0  0  1  ...    \n7663    5.0     3.0      1       0                   0  0  0  0  0  1  ...    \n7664   16.0     3.5      1       0                   0  0  0  1  0  0  ...    \n7665   13.0     3.5      1       0                   0  0  0  1  0  0  ...    \n7666   47.0     3.5      0       0                   0  0  0  0  1  0  ...    \n7667    8.0     3.5      0       0                   0  0  0  0  1  0  ...    \n7668   53.0     4.5      1       0                   0  0  0  1  0  0  ...    \n7669   11.0     4.5      1       0                   0  0  0  1  0  0  ...    \n7670   14.0     3.5      1       0                   0  0  0  1  0  0  ...    \n7671   11.0     3.5      1       0                   0  0  0  1  0  0  ...    \n7672   13.0     2.0      0       0                   0  0  1  0  0  0  ...    \n7673   10.0     4.0      1       0                   0  0  0  0  0  1  ...    \n7674   17.0     3.5      0       0                   0  0  0  1  0  0  ...    \n7675    7.0     3.5      0       0                   0  0  0  1  0  0  ...    \n7676   37.0     4.5      0       0                   0  0  1  0  0  0  ...    \n7677   13.0     4.5      0       0                   0  0  1  0  0  0  ...    \n7678    2.0     4.5      1       0                   0  0  0  0  1  0  ...    \n7679   21.0     2.0      1       0                   0  1  0  0  0  0  ...    \n\n      11435  11436  11692  11693  11694  2015  2016  2017  2018  2019  \n0         0      0      0      0      0     0     1     0     0     0  \n1         0      0      0      0      0     0     0     1     0     0  \n2         0      0      0      0      0     0     0     0     1     0  \n3         0      0      0      0      0     0     1     0     0     0  \n4         0      0      0      0      0     0     0     1     0     0  \n5         0      0      0      0      0     0     0     0     1     0  \n6         0      0      0      0      0     1     0     0     0     0  \n7         0      0      0      0      0     1     0     0     0     0  \n8         0      0      0      0      0     0     1     0     0     0  \n9         0      0      0      0      0     0     1     0     0     0  \n10        0      0      0      0      0     0     1     0     0     0  \n11        0      0      0      0      0     0     0     1     0     0  \n12        0      0      0      0      0     0     0     0     1     0  \n13        0      0      0      0      0     0     0     0     1     0  \n14        0      0      0      0      0     0     1     0     0     0  \n15        0      0      0      0      0     0     1     0     0     0  \n16        0      0      0      0      0     0     1     0     0     0  \n17        0      0      0      0      0     0     1     0     0     0  \n18        0      0      0      0      0     0     0     1     0     0  \n19        0      0      0      0      0     0     0     0     1     0  \n20        0      0      0      0      0     0     0     0     1     0  \n21        0      0      0      0      0     0     0     0     1     0  \n22        0      0      0      0      0     0     0     0     1     0  \n23        0      0      0      0      0     0     0     0     1     0  \n24        0      0      0      0      0     0     0     0     0     1  \n25        0      0      0      0      0     1     0     0     0     0  \n26        0      0      0      0      0     1     0     0     0     0  \n27        0      0      0      0      0     1     0     0     0     0  \n28        0      0      0      0      0     1     0     0     0     0  \n29        0      0      0      0      0     0     0     1     0     0  \n...     ...    ...    ...    ...    ...   ...   ...   ...   ...   ...  \n7650      0      0      0      0      0     0     0     0     1     0  \n7651      0      0      0      0      0     0     0     0     1     0  \n7652      0      0      0      0      0     0     0     0     1     0  \n7653      0      0      0      0      0     0     0     0     0     1  \n7654      0      0      0      0      0     0     0     0     0     1  \n7655      0      0      0      0      0     0     0     0     1     0  \n7656      0      0      0      0      0     0     0     0     1     0  \n7657      0      0      0      0      0     0     0     0     1     0  \n7658      0      0      0      0      0     0     0     0     1     0  \n7659      0      0      0      0      0     0     0     0     1     0  \n7660      0      0      0      0      0     0     0     0     1     0  \n7661      0      0      0      0      0     0     0     0     1     0  \n7662      0      0      0      0      0     0     0     0     0     1  \n7663      0      0      0      0      0     0     0     0     0     1  \n7664      0      0      0      0      0     0     0     0     1     0  \n7665      0      0      0      0      0     0     0     0     0     1  \n7666      0      0      0      0      0     0     0     0     1     0  \n7667      0      0      0      0      0     0     0     0     1     0  \n7668      0      0      0      0      0     0     0     0     1     0  \n7669      0      0      0      0      0     0     0     0     1     0  \n7670      0      0      0      0      0     0     0     0     1     0  \n7671      0      0      0      0      0     0     0     0     0     1  \n7672      0      0      0      0      0     0     0     0     1     0  \n7673      0      0      0      0      0     0     0     0     0     1  \n7674      0      0      0      0      0     0     0     0     1     0  \n7675      0      0      0      0      0     0     0     0     0     1  \n7676      0      0      0      0      0     0     0     0     0     1  \n7677      0      0      0      0      0     0     0     0     0     1  \n7678      0      0      0      0      0     0     0     0     0     1  \n7679      0      0      0      0      0     0     0     0     0     1  \n\n[7680 rows x 197 columns]", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>rating</th>\n      <th>price</th>\n      <th>summer</th>\n      <th>initial_inspection</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>...</th>\n      <th>11435</th>\n      <th>11436</th>\n      <th>11692</th>\n      <th>11693</th>\n      <th>11694</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>13.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>18.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>8.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>24.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>51.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>33.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>24.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>27.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>46.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>12.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>12.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7650</th>\n      <td>24.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7651</th>\n      <td>36.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7652</th>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7653</th>\n      <td>28.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7654</th>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7655</th>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7656</th>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7657</th>\n      <td>12.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7658</th>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7659</th>\n      <td>13.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7660</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7661</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7662</th>\n      <td>42.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7663</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7664</th>\n      <td>16.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7665</th>\n      <td>13.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7666</th>\n      <td>47.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7667</th>\n      <td>8.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7668</th>\n      <td>53.0</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7669</th>\n      <td>11.0</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7670</th>\n      <td>14.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7671</th>\n      <td>11.0</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7672</th>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7673</th>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7674</th>\n      <td>17.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7675</th>\n      <td>7.0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7676</th>\n      <td>37.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7677</th>\n      <td>13.0</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7678</th>\n      <td>2.0</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7679</th>\n      <td>21.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7680 rows \ufffd 197 columns</p>\n</div>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 209, 
            "cell_type": "code", 
            "source": "df.columns", 
            "outputs": [
                {
                    "execution_count": 209, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Index(['score', 'rating', 'price', 'summer', 'initial_inspection', '0', '1',\n       '2', '3', '4',\n       ...\n       '11435', '11436', '11692', '11693', '11694', '2015', '2016', '2017',\n       '2018', '2019'],\n      dtype='object', length=197)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "### Linear Regression", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 261, 
            "cell_type": "code", 
            "source": "#features = ['boro', 'zipcode', 'rating', 'price', 'summer', 'initial_inspection', 'year']\n#features = ['rating', 'price', 'summer', 'initial_inspection']\n\nX = df.drop(columns=['score'])\ny = df['score']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 262, 
            "cell_type": "code", 
            "source": "ss = StandardScaler()\nX_train_sc = ss.fit_transform(X_train)\nX_test_sc = ss.transform(X_test)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 263, 
            "cell_type": "code", 
            "source": "lr = LinearRegression()\nlasso = LassoCV()\nridge = RidgeCV()\nelastic = ElasticNetCV()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 264, 
            "cell_type": "code", 
            "source": "cross_val_score(lr, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 264, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-1.6639646650013112e+27"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 265, 
            "cell_type": "code", 
            "source": "lr.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 265, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 266, 
            "cell_type": "code", 
            "source": "lr.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 266, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.04705382263954827"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 267, 
            "cell_type": "code", 
            "source": "lr.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 267, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-3.852025052128461e+23"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 268, 
            "cell_type": "code", 
            "source": "cross_val_score(lasso, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 268, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.007272646653613009"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 269, 
            "cell_type": "code", 
            "source": "lasso.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 269, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "LassoCV(alphas=None, copy_X=True, cv='warn', eps=0.001, fit_intercept=True,\n    max_iter=1000, n_alphas=100, n_jobs=None, normalize=False,\n    positive=False, precompute='auto', random_state=None,\n    selection='cyclic', tol=0.0001, verbose=False)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 270, 
            "cell_type": "code", 
            "source": "lasso.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 270, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.030632489294603164"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 271, 
            "cell_type": "code", 
            "source": "lasso.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 271, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.016853027146746524"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 272, 
            "cell_type": "code", 
            "source": "cross_val_score(ridge, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 272, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.021891653650390513"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 273, 
            "cell_type": "code", 
            "source": "ridge.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 273, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "RidgeCV(alphas=array([ 0.1,  1. , 10. ]), cv=None, fit_intercept=True,\n    gcv_mode=None, normalize=False, scoring=None, store_cv_values=False)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 274, 
            "cell_type": "code", 
            "source": "ridge.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 274, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.06628854987713584"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 275, 
            "cell_type": "code", 
            "source": "ridge.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 275, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.0025629739111628913"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 276, 
            "cell_type": "code", 
            "source": "cross_val_score(elastic, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 276, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.008978284305931727"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 277, 
            "cell_type": "code", 
            "source": "elastic.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 277, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "ElasticNetCV(alphas=None, copy_X=True, cv='warn', eps=0.001,\n       fit_intercept=True, l1_ratio=0.5, max_iter=1000, n_alphas=100,\n       n_jobs=None, normalize=False, positive=False, precompute='auto',\n       random_state=None, selection='cyclic', tol=0.0001, verbose=0)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 278, 
            "cell_type": "code", 
            "source": "elastic.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 278, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.03173187345158024"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 279, 
            "cell_type": "code", 
            "source": "elastic.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 279, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.017015292556125994"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "### Randomforest Regression", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 281, 
            "cell_type": "code", 
            "source": "#features = ['boro', 'zipcode', 'rating', 'price', 'summer', 'initial_inspection', 'year']\n#features = ['rating', 'price', 'summer', 'initial_inspection']\n\nX = df.drop(columns=['score'])\ny = df['score']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 282, 
            "cell_type": "code", 
            "source": "ss = StandardScaler()\nX_train_sc = ss.fit_transform(X_train)\nX_test_sc = ss.transform(X_test)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 283, 
            "cell_type": "code", 
            "source": "rf = RandomForestRegressor()\net = ExtraTreeRegressor()\ndt = DecisionTreeRegressor()\nbr = BaggingRegressor()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 284, 
            "cell_type": "code", 
            "source": "cross_val_score(rf, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
                }, 
                {
                    "execution_count": 284, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.27577299832066515"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 285, 
            "cell_type": "code", 
            "source": "rf.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
                }, 
                {
                    "execution_count": 285, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n           oob_score=False, random_state=None, verbose=0, warm_start=False)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 286, 
            "cell_type": "code", 
            "source": "rf.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 286, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.5704212883900658"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 287, 
            "cell_type": "code", 
            "source": "rf.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 287, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.22740417866824525"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 288, 
            "cell_type": "code", 
            "source": "cross_val_score(et, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 288, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.7880005059612897"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 289, 
            "cell_type": "code", 
            "source": "et.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 289, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n          max_leaf_nodes=None, min_impurity_decrease=0.0,\n          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n          min_weight_fraction_leaf=0.0, random_state=None,\n          splitter='random')"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 290, 
            "cell_type": "code", 
            "source": "et.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 290, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.6968540402686121"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 291, 
            "cell_type": "code", 
            "source": "et.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 291, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.5797874453449483"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 292, 
            "cell_type": "code", 
            "source": "cross_val_score(dt, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 292, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.7794024759804333"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 293, 
            "cell_type": "code", 
            "source": "dt.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 293, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n           max_leaf_nodes=None, min_impurity_decrease=0.0,\n           min_impurity_split=None, min_samples_leaf=1,\n           min_samples_split=2, min_weight_fraction_leaf=0.0,\n           presort=False, random_state=None, splitter='best')"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 294, 
            "cell_type": "code", 
            "source": "dt.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 294, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.6968540402686121"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 295, 
            "cell_type": "code", 
            "source": "dt.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 295, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.5870497997626054"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 296, 
            "cell_type": "code", 
            "source": "cross_val_score(br, X_train_sc, y_train).mean()", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
                }, 
                {
                    "execution_count": 296, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.28054380977602533"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 297, 
            "cell_type": "code", 
            "source": "br.fit(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 297, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "BaggingRegressor(base_estimator=None, bootstrap=True,\n         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,\n         verbose=0, warm_start=False)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 298, 
            "cell_type": "code", 
            "source": "br.score(X_train_sc, y_train)", 
            "outputs": [
                {
                    "execution_count": 298, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.5805286011095445"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 299, 
            "cell_type": "code", 
            "source": "br.score(X_test_sc, y_test)", 
            "outputs": [
                {
                    "execution_count": 299, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "-0.21597542736771858"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "### Neural Network", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 300, 
            "cell_type": "code", 
            "source": "#features = ['boro', 'zipcode', 'rating', 'price', 'summer', 'initial_inspection', 'year']\n\nX = df.drop(columns=['score'])\ny = df['score']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 301, 
            "cell_type": "code", 
            "source": "ss = StandardScaler()", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 302, 
            "cell_type": "code", 
            "source": "X_train_sc = ss.fit_transform(X_train)\nX_test_sc = ss.transform(X_test)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  \n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 303, 
            "cell_type": "code", 
            "source": "model = Sequential()\n\n# First hidden layer\nmodel.add(Dense(20, activation='relu', input_dim=X_train.shape[1]))\n\n# Second hidden layer\nmodel.add(Dense(10, activation='relu'))\n\n# For regression, the output layer is ALWAYS:\n# 1 neuron\n# No activation function\nmodel.add(Dense(1, activation=None))", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 304, 
            "cell_type": "code", 
            "source": "model.compile(loss='mean_squared_error', optimizer='adam')", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 305, 
            "cell_type": "code", 
            "source": "model.fit(X_train_sc, y_train,\n         validation_data=(X_test_sc, y_test),\n         epochs=10)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 5760 samples, validate on 1920 samples\nEpoch 1/10\n5760/5760 [==============================] - 1s 145us/step - loss: 253.4654 - val_loss: 143.2671\nEpoch 2/10\n5760/5760 [==============================] - 0s 62us/step - loss: 119.9557 - val_loss: 118.3867\nEpoch 3/10\n5760/5760 [==============================] - 0s 61us/step - loss: 111.8309 - val_loss: 117.3738\nEpoch 4/10\n5760/5760 [==============================] - 0s 60us/step - loss: 110.3305 - val_loss: 117.3512\nEpoch 5/10\n5760/5760 [==============================] - 0s 62us/step - loss: 109.5519 - val_loss: 117.4929\nEpoch 6/10\n5760/5760 [==============================] - 0s 61us/step - loss: 109.2362 - val_loss: 117.6570\nEpoch 7/10\n5760/5760 [==============================] - 0s 63us/step - loss: 108.9818 - val_loss: 117.4042\nEpoch 8/10\n5760/5760 [==============================] - 0s 62us/step - loss: 108.7957 - val_loss: 117.6183\nEpoch 9/10\n5760/5760 [==============================] - 0s 63us/step - loss: 108.5771 - val_loss: 117.6240\nEpoch 10/10\n5760/5760 [==============================] - 0s 63us/step - loss: 108.2844 - val_loss: 117.3221\n"
                }, 
                {
                    "execution_count": 305, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x144cd2320>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 307, 
            "cell_type": "code", 
            "source": "preds = model.predict(X_test_sc)", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 306, 
            "cell_type": "code", 
            "source": "from sklearn.metrics import r2_score", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 310, 
            "cell_type": "code", 
            "source": "y_test[:20]", 
            "outputs": [
                {
                    "execution_count": 310, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "5992    41.0\n4466    10.0\n1575    12.0\n4787     5.0\n3538    22.0\n1193    12.0\n4714    17.0\n4086    17.0\n37      16.0\n1405    11.0\n6643    24.0\n6559    13.0\n6820    42.0\n6280    18.0\n1758    11.0\n2521    58.0\n7609    10.0\n6317    12.0\n2115    12.0\n1669    13.0\nName: score, dtype: float64"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 315, 
            "cell_type": "code", 
            "source": "plt.hist(y, bins=20)", 
            "outputs": [
                {
                    "execution_count": 315, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "(array([1.006e+03, 4.073e+03, 1.057e+03, 7.450e+02, 3.570e+02, 1.850e+02,\n        1.090e+02, 6.800e+01, 4.200e+01, 1.700e+01, 1.000e+01, 3.000e+00,\n        2.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 2.000e+00,\n        0.000e+00, 1.000e+00]),\n array([  0.  ,   6.85,  13.7 ,  20.55,  27.4 ,  34.25,  41.1 ,  47.95,\n         54.8 ,  61.65,  68.5 ,  75.35,  82.2 ,  89.05,  95.9 , 102.75,\n        109.6 , 116.45, 123.3 , 130.15, 137.  ]),\n <a list of 20 Patch objects>)"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    }, 
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "source": "plt.scatter(df['price'], df['score'])\nplt.xlabel('Price', size=15)\nplt.ylabel('Score', size=15)", 
            "outputs": [
                {
                    "ename": "NameError", 
                    "evalue": "name 'plt' is not defined", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-1-c55f505ec48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
                    ], 
                    "output_type": "error"
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 312, 
            "cell_type": "code", 
            "source": "preds[:20]", 
            "outputs": [
                {
                    "execution_count": 312, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([[15.330189 ],\n       [14.361861 ],\n       [10.199347 ],\n       [11.204885 ],\n       [20.413912 ],\n       [13.940799 ],\n       [21.507778 ],\n       [12.058456 ],\n       [15.62653  ],\n       [17.076868 ],\n       [13.511232 ],\n       [15.5946865],\n       [12.611149 ],\n       [13.684148 ],\n       [13.329492 ],\n       [20.522324 ],\n       [14.181321 ],\n       [12.534037 ],\n       [15.289196 ],\n       [13.018463 ]], dtype=float32)"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": 308, 
            "cell_type": "code", 
            "source": "r2_score(y_test, preds )", 
            "outputs": [
                {
                    "execution_count": 308, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.004144809809918493"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "source": "", 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}